http://tidytextmining.com/topicmodeling.html#fig:topiccompare

```{r}
library(topicmodels)
library(tidyverse)
library(tidytext)
library(ggplot2)
library(dplyr)
library(tidyr)
```



```{r}
data("AssociatedPress")
AssociatedPress
```

# Fit topic modeil

```{r}
# set a seed so that the output of the model is predictable
ap_lda <- LDA(AssociatedPress, k = 2, control = list(seed = 1234))
```

# Peek at first output

```{r}
ap_lda
glimpse(ap_lda)
```

Analysing model

```{r}
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics
```

# See top terms

```{r}
ap_top_terms <- ap_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

ap_top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()
```

```{r}
beta_spread <- ap_topics %>%
  mutate(topic = paste0("topic", topic)) %>%
  spread(topic, beta) %>%
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1))


barplot(beta_spread$log_ratio, horiz = TRUE)
```


```{r}
ap_documents <- tidy(ap_lda, matrix = "gamma")
ap_documents

```

# Check document 6

```{r}

tidy(AssociatedPress) %>%
  filter(document == 6) %>%
  arrange(desc(count))

```



# Set book titles

```{r}
titles <- c("Twenty Thousand Leagues under the Sea", "The War of the Worlds",
            "Pride and Prejudice", "Great Expectations")
```


# Download books

```{r}
library(gutenbergr)

books <- gutenberg_works(title %in% titles) %>%
  gutenberg_download(meta_fields = "title")
```

```{r}
library(stringr)

# divide into documents, each representing one chapter
by_chapter <- books %>%
  group_by(title) %>%
  mutate(chapter = cumsum(str_detect(text, regex("^chapter ", ignore_case = TRUE)))) %>%
  ungroup() %>%
  filter(chapter > 0) %>%
  unite(document, title, chapter)

# split into words
by_chapter_word <- by_chapter %>%
  unnest_tokens(word, text)

# find document-word counts
word_counts <- by_chapter_word %>%
  anti_join(stop_words) %>%
  count(document, word, sort = TRUE) %>%
  ungroup()

word_counts
```

# Create DocumentTermMatrix

```{r}
chapters_dtm <- word_counts %>%
  cast_dtm(document, word, n)

chapters_dtm
```

# Create four topic model

```{r}
chapters_lda <- LDA(chapters_dtm, k = 4, control = list(seed = 1234))
chapters_lda


```

```{r}
assignments <- augment(chapters_lda, data = chapters_dtm)
assignments
```


```{r}
assignments <- assignments %>%
  separate(document, c("title", "chapter"), sep = "_", convert = TRUE) %>%
  inner_join(book_topics, by = c(".topic" = "topic"))

assignments
```

